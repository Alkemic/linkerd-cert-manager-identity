apiVersion: v1
kind: Pod
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    config.linkerd.io/default-inbound-policy: all-unauthenticated
    linkerd.io/created-by: linkerd/cli stable-2.12.3
    linkerd.io/proxy-version: stable-2.12.3
    linkerd.io/trust-root-sha256: 73b920e7ab22cb4bf5923faee5e827b733ea28969e51e0ca75594dd5559797f9
  creationTimestamp: "2023-03-21T14:05:35Z"
  generateName: linkerd-identity-7c8d9cb84b-
  labels:
    linkerd.io/control-plane-component: identity
    linkerd.io/control-plane-ns: linkerd
    linkerd.io/proxy-deployment: linkerd-identity
    linkerd.io/workload-ns: linkerd
    pod-template-hash: 7c8d9cb84b
  name: linkerd-identity-7c8d9cb84b-zkkdd
  namespace: linkerd
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: linkerd-identity-7c8d9cb84b
    uid: 0cd4c298-4825-4189-a793-da7fc967d3be
  resourceVersion: "12338"
  uid: be23ab30-29ec-4dba-8c95-4db6ac9cc7f3
spec:
  containers:
  - args:
    - identity
    - -log-level=info
    - -log-format=plain
    - -controller-namespace=linkerd
    - -identity-trust-domain=cluster.local
    - -identity-issuance-lifetime=24h0m0s
    - -identity-clock-skew-allowance=20s
    - -identity-scheme=kubernetes.io/tls
    - -enable-pprof=false
    env:
    - name: LINKERD_DISABLED
      value: linkerd-await cannot block the identity controller
    image: alkemic/linekrd-identity-cert-manager:v0.0.1.5
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /ping
        port: 9990
        scheme: HTTP
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    name: identity
    ports:
    - containerPort: 8080
      name: grpc
      protocol: TCP
    - containerPort: 9990
      name: admin-http
      protocol: TCP
    readinessProbe:
      failureThreshold: 7
      httpGet:
        path: /ready
        port: 9990
        scheme: HTTP
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    resources: {}
    securityContext:
      allowPrivilegeEscalation: false
      runAsUser: 2103
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/linkerd/identity/issuer
      name: identity-issuer
    - mountPath: /var/run/linkerd/identity/trust-roots/
      name: trust-roots
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-frspb
      readOnly: true
  - env:
    - name: _pod_name
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: _pod_ns
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    - name: _pod_nodeName
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: LINKERD2_PROXY_INBOUND_PORTS_REQUIRE_TLS
      value: "8080"
    - name: LINKERD2_PROXY_LOG
      value: warn,linkerd=info
    - name: LINKERD2_PROXY_LOG_FORMAT
      value: plain
    - name: LINKERD2_PROXY_DESTINATION_SVC_ADDR
      value: linkerd-dst-headless.linkerd.svc.cluster.local.:8086
    - name: LINKERD2_PROXY_DESTINATION_PROFILE_NETWORKS
      value: 10.0.0.0/8,100.64.0.0/10,172.16.0.0/12,192.168.0.0/16
    - name: LINKERD2_PROXY_POLICY_SVC_ADDR
      value: linkerd-policy.linkerd.svc.cluster.local.:8090
    - name: LINKERD2_PROXY_POLICY_WORKLOAD
      value: $(_pod_ns):$(_pod_name)
    - name: LINKERD2_PROXY_INBOUND_DEFAULT_POLICY
      value: all-unauthenticated
    - name: LINKERD2_PROXY_POLICY_CLUSTER_NETWORKS
      value: 10.0.0.0/8,100.64.0.0/10,172.16.0.0/12,192.168.0.0/16
    - name: LINKERD2_PROXY_INBOUND_CONNECT_TIMEOUT
      value: 100ms
    - name: LINKERD2_PROXY_OUTBOUND_CONNECT_TIMEOUT
      value: 1000ms
    - name: LINKERD2_PROXY_CONTROL_LISTEN_ADDR
      value: 0.0.0.0:4190
    - name: LINKERD2_PROXY_ADMIN_LISTEN_ADDR
      value: 0.0.0.0:4191
    - name: LINKERD2_PROXY_OUTBOUND_LISTEN_ADDR
      value: 127.0.0.1:4140
    - name: LINKERD2_PROXY_INBOUND_LISTEN_ADDR
      value: 0.0.0.0:4143
    - name: LINKERD2_PROXY_INBOUND_IPS
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIPs
    - name: LINKERD2_PROXY_INBOUND_PORTS
      value: 8080,9990
    - name: LINKERD2_PROXY_DESTINATION_PROFILE_SUFFIXES
      value: svc.cluster.local.
    - name: LINKERD2_PROXY_INBOUND_ACCEPT_KEEPALIVE
      value: 10000ms
    - name: LINKERD2_PROXY_OUTBOUND_CONNECT_KEEPALIVE
      value: 10000ms
    - name: LINKERD2_PROXY_INBOUND_PORTS_DISABLE_PROTOCOL_DETECTION
      value: 25,587,3306,4444,5432,6379,9300,11211
    - name: LINKERD2_PROXY_DESTINATION_CONTEXT
      value: |
        {"ns":"$(_pod_ns)", "nodeName":"$(_pod_nodeName)"}
    - name: _pod_sa
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.serviceAccountName
    - name: _l5d_ns
      value: linkerd
    - name: _l5d_trustdomain
      value: cluster.local
    - name: LINKERD2_PROXY_IDENTITY_DIR
      value: /var/run/linkerd/identity/end-entity
    - name: LINKERD2_PROXY_IDENTITY_TRUST_ANCHORS
      valueFrom:
        configMapKeyRef:
          key: ca-bundle.crt
          name: linkerd-identity-trust-roots
    - name: LINKERD2_PROXY_IDENTITY_TOKEN_FILE
      value: /var/run/secrets/tokens/linkerd-identity-token
    - name: LINKERD2_PROXY_IDENTITY_SVC_ADDR
      value: localhost.:8080
    - name: LINKERD2_PROXY_IDENTITY_LOCAL_NAME
      value: $(_pod_sa).$(_pod_ns).serviceaccount.identity.linkerd.cluster.local
    - name: LINKERD2_PROXY_IDENTITY_SVC_NAME
      value: linkerd-identity.linkerd.serviceaccount.identity.linkerd.cluster.local
    - name: LINKERD2_PROXY_DESTINATION_SVC_NAME
      value: linkerd-destination.linkerd.serviceaccount.identity.linkerd.cluster.local
    - name: LINKERD2_PROXY_POLICY_SVC_NAME
      value: linkerd-destination.linkerd.serviceaccount.identity.linkerd.cluster.local
    image: cr.l5d.io/linkerd/proxy:stable-2.12.3
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /live
        port: 4191
        scheme: HTTP
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    name: linkerd-proxy
    ports:
    - containerPort: 4143
      name: linkerd-proxy
      protocol: TCP
    - containerPort: 4191
      name: linkerd-admin
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /ready
        port: 4191
        scheme: HTTP
      initialDelaySeconds: 2
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    resources: {}
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsUser: 2102
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /var/run/linkerd/identity/end-entity
      name: linkerd-identity-end-entity
    - mountPath: /var/run/secrets/tokens
      name: linkerd-identity-token
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-frspb
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  initContainers:
  - args:
    - --incoming-proxy-port
    - "4143"
    - --outgoing-proxy-port
    - "4140"
    - --proxy-uid
    - "2102"
    - --inbound-ports-to-ignore
    - 4190,4191,4567,4568
    - --outbound-ports-to-ignore
    - 443,6443
    image: cr.l5d.io/linkerd/proxy-init:v2.0.0
    imagePullPolicy: IfNotPresent
    name: linkerd-init
    resources:
      limits:
        cpu: 100m
        memory: 20Mi
      requests:
        cpu: 100m
        memory: 20Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        add:
        - NET_ADMIN
        - NET_RAW
      privileged: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 65534
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /run
      name: linkerd-proxy-init-xtables-lock
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-frspb
      readOnly: true
  nodeName: linkerd-control-plane
  nodeSelector:
    kubernetes.io/os: linux
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: linkerd-identity
  serviceAccountName: linkerd-identity
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: identity-issuer
    secret:
      defaultMode: 420
      secretName: linkerd-identity-issuer
  - configMap:
      defaultMode: 420
      name: linkerd-identity-trust-roots
    name: trust-roots
  - emptyDir: {}
    name: linkerd-proxy-init-xtables-lock
  - name: linkerd-identity-token
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          audience: identity.l5d.io
          expirationSeconds: 86400
          path: linkerd-identity-token
  - emptyDir:
      medium: Memory
    name: linkerd-identity-end-entity
  - name: kube-api-access-frspb
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-03-21T14:05:37Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-03-21T14:05:35Z"
    message: 'containers with unready status: [identity linkerd-proxy]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-03-21T14:05:35Z"
    message: 'containers with unready status: [identity linkerd-proxy]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-03-21T14:05:35Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://f49c26288a47c947ae0c99e28843bdca435d97a2ff6875dd398e33915feb8720
    image: docker.io/alkemic/linekrd-identity-cert-manager:v0.0.1.5
    imageID: docker.io/alkemic/linekrd-identity-cert-manager@sha256:8a5ff5d852a635767a9146825b0a4e78bf73d6b98fd9117701c328e7f87ec85b
    lastState:
      terminated:
        containerID: containerd://f49c26288a47c947ae0c99e28843bdca435d97a2ff6875dd398e33915feb8720
        exitCode: 0
        finishedAt: "2023-03-21T14:21:16Z"
        reason: Completed
        startedAt: "2023-03-21T14:20:36Z"
    name: identity
    ready: false
    restartCount: 9
    started: false
    state:
      waiting:
        message: back-off 5m0s restarting failed container=identity pod=linkerd-identity-7c8d9cb84b-zkkdd_linkerd(be23ab30-29ec-4dba-8c95-4db6ac9cc7f3)
        reason: CrashLoopBackOff
  - containerID: containerd://44512b61e0a7ac1b84ade8ff62b3c43d74d75ea83e5d73eb635948faa2b4de0f
    image: cr.l5d.io/linkerd/proxy:stable-2.12.3
    imageID: cr.l5d.io/linkerd/proxy@sha256:8d32f8493c9c36bf403c3c440125b4bc96fc55b054f4ad084027c0aaf5093263
    lastState: {}
    name: linkerd-proxy
    ready: false
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-21T14:05:38Z"
  hostIP: 172.18.0.2
  initContainerStatuses:
  - containerID: containerd://5cd1e5c9b507273c94c92d1cb2f29cd6eb1e8fb8e23ba32afa96de50d3e56f0d
    image: cr.l5d.io/linkerd/proxy-init:v2.0.0
    imageID: cr.l5d.io/linkerd/proxy-init@sha256:7d5e66b9e176b1ebbdd7f40b6385d1885e82c80a06f4c6af868247bb1dffe262
    lastState: {}
    name: linkerd-init
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: containerd://5cd1e5c9b507273c94c92d1cb2f29cd6eb1e8fb8e23ba32afa96de50d3e56f0d
        exitCode: 0
        finishedAt: "2023-03-21T14:05:37Z"
        reason: Completed
        startedAt: "2023-03-21T14:05:37Z"
  phase: Running
  podIP: 10.244.0.17
  podIPs:
  - ip: 10.244.0.17
  qosClass: Burstable
  startTime: "2023-03-21T14:05:35Z"
